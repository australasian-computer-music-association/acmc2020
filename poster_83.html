


<!DOCTYPE html>
<html lang="en">
  <head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <link rel="stylesheet" href="static/css/main.css" />
    <link rel="stylesheet" href="static/css/lazy_load.css" />
    <link rel="stylesheet" href="static/css/typeahead.css" />

    <!-- External Javascript libs  -->
    <script src="https://d3js.org/d3.v5.min.js"></script>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
      integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
      integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
      integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"
      integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.24.0/moment.min.js"
      integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/moment-timezone/0.5.28/moment-timezone-with-data.min.js"
      integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
      crossorigin="anonymous"
    ></script>

    <!-- Library libs -->
    <script src="static/js/typeahead.bundle.js"></script>

    <!-- External CSS -->
    <link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
      integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
      crossorigin="anonymous"
    />

    <!-- External Fonts -->
    <link
      href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap"
      rel="stylesheet"
    />

    <title>ACMC 2020: Darshan with a Pelican: Multiplicities (2020)</title>
    
<meta name="citation_title" content="Darshan with a Pelican: Multiplicities (2020)" />

<meta name="citation_author" content="Warren Burt" />

<meta name="citation_publication_date" content="July 2020" />
<meta name="citation_conference_title" content="Acmc2020: Inclusion" />
<meta name="citation_inbook_title" content="ACMC 2020: Proceedings of the 2020 Australasian Computer Music Conference" />
<meta name="citation_abstract" content="
Recorded sounds routed in space.

This began on July 18, 2019.  We were driving on the Bellarine Peninsula, southwest of Melbourne, when, on a whim, I said, “Let’s go down to Swan Bay.”  So we did, and in the car park was a pelican.  It came right up to me, and we had a good eye-to-eye session.  In Hinduism, having eye contact with a statue of a god is called Darshan, and the pelican and I seemed to have that kind of a relationship.  Maybe it wanted food, but it stayed well beyond the time when it was clear that I didn’t have any food to give.  So we just sat there, in silent communion, for about 20 minutes.  It struck me that there was a complete juxtaposition of non-intersecting consciousnesses there.  We were both comfortable in each other’s presence, but as for the details of our communication, I would be at a loss to say.  

I have frequently written pieces in the past where various layers of sound are juxtaposed, which layers frequently could be viewed as having nothing to do with each other.  And I’m happy to let those layers of sound co-exist.  Maybe like the pelican and I, they eventually begin to make their own kind of sense.  So here we have five different layers, each of which is made in a different way, and each of which has its own kind of sound motion through space.  The five layers are: One: “Freehand,” which are freehand drawings made in Procreate and then transferred into Virtual ANS3.  That’s a program, based on the ANS synthesizer in Moscow, which allows drawings to be read as spectrograms for sound.  Two: “miRacks,” which are textures made from multiple microtonal transpositions of electronic melodies made in 2018-9 with Dhalang MG (microtonal synthesis and composing program).  These melodies are placed in Antonio Tuzzi’s “Sussudio” multiple sample module in the iOS version of VCVRack, called “miRack.”  Up to six different versions of each melody can be heard at once – and these melodies are transposed to pitch levels determined by the original microtonal scale the melody was in.  Three: “Piano Sequences” – a sampled piano in Thumbjam is tuned to a Harry Partch 29-note-to-the-octave scale – the one he tuned his Diamond Marimba to.  Two textures are made – first, a set of chords (mostly stacked fifths), played on a Diamond Marimba style keyboard (made in Lemur); and second, a monophonic melody controlled by the Markov chain generation module in Dhalang MG.  If the first texture seems to contain more than a passing reference to some pieces by Howard Skempton, the second may blushingly nod in the direction of John Cage’s “Cheap Imitation,” which is itself a faintly embarrassed cousin of Erik Satie’s “Socrate.”  The two textures are juxtaposed for the final sequence in the piece.  Four: “Virtual ANS Streetscapes.”  For many months now, I’ve been wandering around Google Maps, seeing streetscapes, some familiar, some never seen before.  Occasionally, I’ll take a screen-capture of a particular street scene.  Then, I’ll load those photos into Virtual ANS, and treat the photos, usually with a 3-step process – edge detect, posterize, and contrast – sometimes in that order, sometimes in another order.  The result will be to reduce the street photography to a series of outlines, which outlines can be heard as spectrographs – quite active ones, with a lot of variation in them (depending on the complexity of the photographs).  The three photos used here are Mohawk St in Cohoes, New York; a landscape photo of Johnstown, Pennsylvania, and the corner of 59th and 3rd in Manhattan.  Each produces a differently articulated sound-scape which form structural bases on which to pile the other textures.  Finally, Five: “Musique Concrete Demos,” which are textures made with various real-world sounds, recorded with my iPhone, that I used to demonstrate various sound modification techniques to my classes.  A back-door screen spring, a Navajo Burden Basket, with many small, high-pitched aluminum bells, a malfunctioning Yogurt fridge in a local supermarket, the sound of corn popping, and the sound of ice-cubes being stirred while making iced-tea.  Each one is time stretched, and most of them are equalized quite high to contrast with the other textures (the exception is the Yogurt fridge, which has an insane amount of bass boost added to its already bass heavy texture).  Originally, each of these five layers was then individually processed with the GRM Tools Spaces 3D plugin – each has its own path around an 8-channel space.  This was intended for a performance on May 22 at the Acousmonium at the INA-GRM in Paris, which features 40 loudspeakers on separate channels.  So with five layers having different independent 8-channel sound routings, the 40 channels of the hall would be totally occupied with moving sounds.  This performance did not happen because the concert was cancelled due to the corona virus.  It is anticipated that the piece will happen at the rescheduled concert on Saturday October 10, circumstances permitting.  However, I also fed each of the five channels of sound independently through the GRM Tools Spaces 3D plugin, this time with 2-channel output, instead of 8-channels.  These stereo processings used different settings and performance techniques than the 8-channel processings did. These five stereo moving-sound channels are then mixed into a stereo mix to make a 2-channel version of the final work, and that’s what is played at this conference.

The five layers don’t all occur at once – there are lots of silences within the individual tracks – but the sound is continuous from beginning to end.  Some of the sounds are abstract, and some veer uncomfortably close to  narrative, but the overall effect is one of formerly unrelated sounds now regarding each other across space and time much like a composer and a pelican in a car park next to Swan Bay in the middle of winter, making their own kind of sense as they sit regarding each other.

20 June 2020, Daylesford, VIC, Warren Burt

" />

<meta name="citation_keywords" content="music" />

<meta name="citation_pdf_url" content="" />


  </head>

  <body>
    <!-- NAV -->
    
    <nav
      class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto"
      id="main-nav"
    >
      <div class="container">
        <a class="navbar-brand" href="index.html">
          <img
             class="logo" src="static/images/acmc2020-logo-nobox.png"
             height="auto"
             width="180px"
          />
        </a>
        
        <button
          class="navbar-toggler"
          type="button"
          data-toggle="collapse"
          data-target="#navbarNav"
          aria-controls="navbarNav"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div
          class="collapse navbar-collapse text-right flex-grow-1"
          id="navbarNav"
        >
          <ul class="navbar-nav ml-auto">
            
            <li class="nav-item ">
              <a class="nav-link" href="index.html">Home</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="calendar.html">Schedule</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="papers.html">Words/Sounds</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="access.html">Access</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="submissions.html">Call</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="policies.html">Policies</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="about.html">Help</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="https://www.youtube.com/channel/UCKK95K68yVuok-qWNS4Z6Jw">YouTube Channel</a>
            </li>
            
          </ul>
        </div>
      </div>
    </nav>
    

    <!-- User Overrides -->
     

    <div class="container">
      <!-- Tabs -->
      <div class="tabs">
         
      </div>
      <!-- Content -->
      <div class="content">
        

<!-- Title -->
<div class="pp-card m-3" style="">
  <div class="card-header">
    <h2 class="card-title main-title text-center" style="">
      Darshan with a Pelican: Multiplicities (2020)
    </h2>
    <h3 class="card-subtitle mb-2 text-muted text-center">
      
      <a href="papers.html?filter=authors&search=Warren Burt" class="text-muted"
        >Warren Burt</a
      >
      
    </h3>
    <!-- <p class="card-text text-center">
      <span class="">Keywords:</span>
      
      <a
        href="papers.html?filter=keywords&search=music"
        class="text-secondary text-decoration-none"
        >music</a
      >
      
    </p> -->
    <div class="text-center p-3">
      
      
      
      
      <a class="card-link" href="http://www.warrenburt.com">web</a>
    </div>
  </div>
</div>

<!-- 



http://www.warrenburt.com -->

<center><img src="static/paper-images/83.jpg" width="80%" /></center>

<div class="border-top my-3"></div>
<div class="row p-4" id="faq">
  <div class="col-12 bd-content">
    <h2 class="text-center">Details</h2>
  </div>
</div>

<h4>Abstract</h4>

<p>Recorded sounds routed in space.</p>
<p>This began on July 18, 2019.  We were driving on the Bellarine Peninsula, southwest of Melbourne, when, on a whim, I said, “Let’s go down to Swan Bay.”  So we did, and in the car park was a pelican.  It came right up to me, and we had a good eye-to-eye session.  In Hinduism, having eye contact with a statue of a god is called Darshan, and the pelican and I seemed to have that kind of a relationship.  Maybe it wanted food, but it stayed well beyond the time when it was clear that I didn’t have any food to give.  So we just sat there, in silent communion, for about 20 minutes.  It struck me that there was a complete juxtaposition of non-intersecting consciousnesses there.  We were both comfortable in each other’s presence, but as for the details of our communication, I would be at a loss to say.  </p>
<p>I have frequently written pieces in the past where various layers of sound are juxtaposed, which layers frequently could be viewed as having nothing to do with each other.  And I’m happy to let those layers of sound co-exist.  Maybe like the pelican and I, they eventually begin to make their own kind of sense.  So here we have five different layers, each of which is made in a different way, and each of which has its own kind of sound motion through space.  The five layers are: One: “Freehand,” which are freehand drawings made in Procreate and then transferred into Virtual ANS3.  That’s a program, based on the ANS synthesizer in Moscow, which allows drawings to be read as spectrograms for sound.  Two: “miRacks,” which are textures made from multiple microtonal transpositions of electronic melodies made in 2018-9 with Dhalang MG (microtonal synthesis and composing program).  These melodies are placed in Antonio Tuzzi’s “Sussudio” multiple sample module in the iOS version of VCVRack, called “miRack.”  Up to six different versions of each melody can be heard at once – and these melodies are transposed to pitch levels determined by the original microtonal scale the melody was in.  Three: “Piano Sequences” – a sampled piano in Thumbjam is tuned to a Harry Partch 29-note-to-the-octave scale – the one he tuned his Diamond Marimba to.  Two textures are made – first, a set of chords (mostly stacked fifths), played on a Diamond Marimba style keyboard (made in Lemur); and second, a monophonic melody controlled by the Markov chain generation module in Dhalang MG.  If the first texture seems to contain more than a passing reference to some pieces by Howard Skempton, the second may blushingly nod in the direction of John Cage’s “Cheap Imitation,” which is itself a faintly embarrassed cousin of Erik Satie’s “Socrate.”  The two textures are juxtaposed for the final sequence in the piece.  Four: “Virtual ANS Streetscapes.”  For many months now, I’ve been wandering around Google Maps, seeing streetscapes, some familiar, some never seen before.  Occasionally, I’ll take a screen-capture of a particular street scene.  Then, I’ll load those photos into Virtual ANS, and treat the photos, usually with a 3-step process – edge detect, posterize, and contrast – sometimes in that order, sometimes in another order.  The result will be to reduce the street photography to a series of outlines, which outlines can be heard as spectrographs – quite active ones, with a lot of variation in them (depending on the complexity of the photographs).  The three photos used here are Mohawk St in Cohoes, New York; a landscape photo of Johnstown, Pennsylvania, and the corner of 59th and 3rd in Manhattan.  Each produces a differently articulated sound-scape which form structural bases on which to pile the other textures.  Finally, Five: “Musique Concrete Demos,” which are textures made with various real-world sounds, recorded with my iPhone, that I used to demonstrate various sound modification techniques to my classes.  A back-door screen spring, a Navajo Burden Basket, with many small, high-pitched aluminum bells, a malfunctioning Yogurt fridge in a local supermarket, the sound of corn popping, and the sound of ice-cubes being stirred while making iced-tea.  Each one is time stretched, and most of them are equalized quite high to contrast with the other textures (the exception is the Yogurt fridge, which has an insane amount of bass boost added to its already bass heavy texture).  Originally, each of these five layers was then individually processed with the GRM Tools Spaces 3D plugin – each has its own path around an 8-channel space.  This was intended for a performance on May 22 at the Acousmonium at the INA-GRM in Paris, which features 40 loudspeakers on separate channels.  So with five layers having different independent 8-channel sound routings, the 40 channels of the hall would be totally occupied with moving sounds.  This performance did not happen because the concert was cancelled due to the corona virus.  It is anticipated that the piece will happen at the rescheduled concert on Saturday October 10, circumstances permitting.  However, I also fed each of the five channels of sound independently through the GRM Tools Spaces 3D plugin, this time with 2-channel output, instead of 8-channels.  These stereo processings used different settings and performance techniques than the 8-channel processings did. These five stereo moving-sound channels are then mixed into a stereo mix to make a 2-channel version of the final work, and that’s what is played at this conference.</p>
<p>The five layers don’t all occur at once – there are lots of silences within the individual tracks – but the sound is continuous from beginning to end.  Some of the sounds are abstract, and some veer uncomfortably close to  narrative, but the overall effect is one of formerly unrelated sounds now regarding each other across space and time much like a composer and a pelican in a car park next to Swan Bay in the middle of winter, making their own kind of sense as they sit regarding each other.</p>
<p>20 June 2020, Daylesford, VIC, Warren Burt</p>

<h4>Bio</h4>

<p>Warren Burt (b 1949): composer, performer, writer, instrument builder, sound poet.  Currently Coordinator of Post Graduate Studies in Music, Box Hill Institute, Melbourne.  Born in the US, moved to Australia in 1975.  Has been involved in music, video, community arts, community radio, education, etc. since arriving.  Currently living and working in Daylesford, Vic.</p>


      </div>
    </div>

    

    <!-- Google Analytics -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=UA-"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "UA-");
    </script>

    <!-- Footer -->
    <footer class="footer bg-light p-4">
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-sm-5">
            <a href="https://computermusic.org.au">
              <img src="/static/images/amca-logo-footer.jpg" style="width: 100%">
            </a>
          </div>
          <div class="col-sm-5" style="border-left: thin solid #000000;">
            <a href="https://cecs.anu.edu.au">
              <img src="/static/images/anu-logo-footer.jpg" style="width: 100%">
            </a>
          </div>
        </div>
        <div class="row">
        </div>
      <p class="float-right"><a href="#">Back to Top</a></p>
      <p class="text-center">Copyright &copy; Australasian Computer Music Association 2020</p>
      </div>
    </footer>

    <!-- Code for hash tags -->
    <script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });
      });
    </script>
    <script src="static/js/lazy_load.js"></script>
    
  </body>
</html>